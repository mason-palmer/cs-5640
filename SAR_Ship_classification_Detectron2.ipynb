{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Extract dataset\n",
        "\n",
        "Powershell: `Get-ChildItem -Filter *.tar.gz | ForEach-Object {\n",
        "    tar -xzf $_.FullName\n",
        "    Remove-Item $_.FullName -Force\n",
        "}`\n",
        "\n",
        "Bash: `for file in *.tar.gz; do\n",
        "    if [ -f \"$file\" ]; then\n",
        "        tar xzvf \"$file\"\n",
        "        rm \"$file\"\n",
        "    fi\n",
        "done`"
      ],
      "metadata": {
        "id": "H9SDPxcPVS0O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBGij_QP6Iaw"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQejie5jNEOc",
        "outputId": "b2cfa0dc-27be-428c-cbc8-193d7a57deb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23W2bqi7LpZO"
      },
      "outputs": [],
      "source": [
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "!pip install rasterio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpuIoBorAOfM"
      },
      "outputs": [],
      "source": [
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.data import detection_utils as utils\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.model_zoo import get_config_file, get_checkpoint_url\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "from detectron2.checkpoint import DetectionCheckpointer\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "import cv2\n",
        "import os\n",
        "import rasterio\n",
        "import os\n",
        "import glob\n",
        "import rasterio\n",
        "import json\n",
        "from shapely.geometry import box, shape\n",
        "from shapely.ops import transform\n",
        "from pyproj import Proj, Transformer\n",
        "\n",
        "import numpy as np\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_images_and_labels(image_path, label_path, output_dir, grid_size):\n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Use rasterio to read the image\n",
        "    with rasterio.open(image_path) as src:\n",
        "        image = src.read()\n",
        "        height, width = src.height, src.width\n",
        "        transform = src.transform\n",
        "        crs = src.crs\n",
        "\n",
        "    # Load COCO labels from GeoJSON\n",
        "    with open(label_path, 'r') as f:\n",
        "        geojson_data = json.load(f)\n",
        "\n",
        "    # Parse COCO labels and convert to pixel coordinates\n",
        "    bounding_boxes = []\n",
        "    for feature in geojson_data['features']:\n",
        "        properties = feature['properties']\n",
        "        geometry = shape(feature['geometry'])\n",
        "\n",
        "        cls = properties['category_id']\n",
        "        if cls in boat_classes:\n",
        "            # Convert geometry to pixel coordinates\n",
        "            transformer = Transformer.from_crs(crs, \"EPSG:4326\", always_xy=True)\n",
        "            geom_transformed = transform(transformer.transform, geometry)\n",
        "\n",
        "            # Get bounding box in pixel coordinates\n",
        "            minx, miny, maxx, maxy = geom_transformed.bounds\n",
        "            bbox = box(minx, miny, maxx, maxy)\n",
        "            x_center = (bbox.bounds[0] + bbox.bounds[2]) / 2 / width\n",
        "            y_center = (bbox.bounds[1] + bbox.bounds[3]) / 2 / height\n",
        "            bbox_width = (bbox.bounds[2] - bbox.bounds[0]) / width\n",
        "            bbox_height = (bbox.bounds[3] - bbox.bounds[1]) / height\n",
        "\n",
        "            bounding_boxes.append([class_mapping[cls], x_center, y_center, bbox_width, bbox_height])\n",
        "\n",
        "    # Split the image into smaller patches\n",
        "    rows, cols = grid_size\n",
        "    patch_height, patch_width = height // rows, width // cols\n",
        "\n",
        "    patch_counter = 0\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            # Compute patch boundaries\n",
        "            start_y, end_y = i * patch_height, (i + 1) * patch_height\n",
        "            start_x, end_x = j * patch_width, (j + 1) * patch_width\n",
        "\n",
        "            # Extract image patch\n",
        "            patch = image[:, start_y:end_y, start_x:end_x]\n",
        "\n",
        "            # Adjust and save the corresponding labels for the patch\n",
        "            patch_labels = []\n",
        "            contains_boat = False\n",
        "            for box in bounding_boxes:\n",
        "                cls, x_center, y_center, bbox_width, bbox_height = box\n",
        "\n",
        "                # Convert to pixel coordinates\n",
        "                x_center_abs = x_center * width\n",
        "                y_center_abs = y_center * height\n",
        "                bbox_width_abs = bbox_width * width\n",
        "                bbox_height_abs = bbox_height * height\n",
        "\n",
        "                # Check if bounding box is within the current patch\n",
        "                if (start_x <= x_center_abs <= end_x) and (start_y <= y_center_abs <= end_y):\n",
        "                    # Adjust bounding box for the new patch\n",
        "                    new_x_center = (x_center_abs - start_x) / patch_width\n",
        "                    new_y_center = (y_center_abs - start_y) / patch_height\n",
        "                    new_bbox_width = bbox_width_abs / patch_width\n",
        "                    new_bbox_height = bbox_height_abs / patch_height\n",
        "\n",
        "                    patch_labels.append(f\"{int(cls)} {new_x_center} {new_y_center} {new_bbox_width} {new_bbox_height}\")\n",
        "                    contains_boat = True\n",
        "\n",
        "            # Save patch only if it contains boat classes\n",
        "            if contains_boat:\n",
        "                print(f\"Saving patch {patch_counter} for image {os.path.basename(image_path)}\")\n",
        "                patch_filename = f\"{os.path.splitext(os.path.basename(image_path))[0]}_{patch_counter}.tif\"\n",
        "                patch_path = f\"{output_dir}/{patch_filename}\"\n",
        "                with rasterio.open(\n",
        "                    patch_path,\n",
        "                    'w',\n",
        "                    driver='GTiff',\n",
        "                    height=patch_height,\n",
        "                    width=patch_width,\n",
        "                    count=image.shape[0],\n",
        "                    dtype=image.dtype,\n",
        "                ) as dst:\n",
        "                    dst.write(patch)\n",
        "\n",
        "                # Save labels for this patch\n",
        "                patch_label_filename = f\"{os.path.splitext(os.path.basename(label_path))[0]}_{patch_counter}.txt\"\n",
        "                patch_label_path = f\"{output_dir}/{patch_label_filename}\"\n",
        "\n",
        "                with open(patch_label_path, 'w') as f:\n",
        "                    for label in patch_labels:\n",
        "                        f.write(label + '\\n')\n",
        "\n",
        "            patch_counter += 1\n",
        "\n",
        "# Split all images and labels in the directory\n",
        "all_tifs = glob.glob(f\"/content/drive/MyDrive/ShipClassification/EO_Train/*.tif\")\n",
        "for tif in all_tifs:\n",
        "    label_path = tif.replace(\".tif\", \".geojson\")\n",
        "    split_images_and_labels(tif, label_path, \"/content/drive/MyDrive/ShipClassification/EO_Train_Split3\", (8, 8))\n"
      ],
      "metadata": {
        "id": "YUkv0LVQVCvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_scene(scene_dir, processed_dir):\n",
        "    # Add stacked image to processed_dir\n",
        "    scene_id = os.path.basename(scene_dir)\n",
        "    combine_sar_channels(f\"{scene_dir}/VV_dB.tif\", f\"{scene_dir}/VH_dB.tif\", f\"{processed_dir}/{scene_id}_stacked.tif\")\n",
        "\n",
        "    # Add label file to processed_dir\n",
        "    convert_csv_to_yolo_labels(f\"{scene_dir}/labels.csv\", processed_dir, scene_dir)\n",
        "\n",
        "    # Split image\n",
        "\n"
      ],
      "metadata": {
        "id": "sbWkplhQUBse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Nl5-_PjAMRQH"
      },
      "outputs": [],
      "source": [
        "# combine VV and VH into a single grayscale channel (if time, compare to split channels)\n",
        "def custom_read_image(file_name, format=None):\n",
        "    import rasterio\n",
        "    import numpy as np\n",
        "\n",
        "    with rasterio.open(file_name) as src:\n",
        "        vv = src.read(1)  # VV polarization\n",
        "        vh = src.read(2)  # VH polarization\n",
        "\n",
        "        # combine into single grayscale ch.\n",
        "        grayscale = (vv + vh) / 2\n",
        "\n",
        "        # Duplicate ch to work with rgb transfer model\n",
        "        image = np.stack([vv, vh, grayscale], axis=-1)  # (H, W, 3)\n",
        "        return image\n",
        "\n",
        "utils.read_image = custom_read_image\n",
        "config_path = \"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "wQXcR8QEA8bO"
      },
      "outputs": [],
      "source": [
        "# Register the dataset\n",
        "register_coco_instances(\"cascade_train_dataset\", {}, \"train_coco.json\", \"/content/drive/MyDrive/ShipClassfication/SAR/Train\")\n",
        "register_coco_instances(\"cascade_val_dataset\", {}, \"validation_coco.json\", \"/content/drive/MyDrive/ShipClassfication/SAR/Val\")\n",
        "# Set up the configuration\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(get_config_file(config_path))  # Use pre-configured Cascade R-CNN\n",
        "cfg.MODEL.PIXEL_MEAN = [123.0, 123.0, 123.0]  # Currently set to three channels for flattened pols\n",
        "cfg.MODEL.PIXEL_STD = [58.0, 58.0, 58.0]     #\n",
        "cfg.DATASETS.TRAIN = (\"cascade_train_dataset\",)\n",
        "cfg.DATASETS.TEST = (\"cascade_val_dataset\",)\n",
        "cfg.DATALOADER.NUM_WORKERS = 0\n",
        "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/ShipClassfication/Checkpoints/Faster_RCNN_1.pth\"\n",
        "cfg.SOLVER.IMS_PER_BATCH = 1\n",
        "cfg.SOLVER.BASE_LR = 0.01\n",
        "cfg.SOLVER.MAX_ITER = 100\n",
        "# cfg.SOLVER.STEPS = [300, 400]\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n",
        "cfg.SOLVER.CHECKPOINT_PERIOD = 50\n",
        "cfg.SOLVER.AMP.ENABLED = True\n",
        "cfg.MODEL.DEVICE = \"cuda\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vzc_4GlBDr8"
      },
      "outputs": [],
      "source": [
        "generation = 7\n",
        "def main():\n",
        "    # Output directory for saving checkpoints and logs\n",
        "    cfg.OUTPUT_DIR = f\"/content/drive/MyDrive/ShipClassfication/Checkpoints/SAR/{generation}\"\n",
        "\n",
        "    cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[8, 16, 32, 64, 128]]  # Smaller anchor sizes\n",
        "    cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.75, 1.0, 1.25]]  # Use default aspect ratios\n",
        "\n",
        "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "    # Train the model\n",
        "    trainer = DefaultTrainer(cfg)\n",
        "    trainer.resume_or_load(resume=True)\n",
        "    trainer.train()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bt20tsEzBH-x"
      },
      "outputs": [],
      "source": [
        "   # Create evaluator and test loader\n",
        "    evaluator = COCOEvaluator(\"cascade_val_dataset\", cfg, False, output_dir=f\"./output_cascade_rcnn{generation}\")\n",
        "    test_loader = build_detection_test_loader(cfg, \"cascade_val_dataset\")\n",
        "    metrics = inference_on_dataset(trainer.model, test_loader, evaluator)\n",
        "\n",
        "    predictions  = []\n",
        "    ground_truth = []\n",
        "    # Perform evaluation\n",
        "    inference_on_dataset(trainer.model, test_loader, evaluator)\n",
        "\n",
        "    # Load the trained model\n",
        "    # cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "    cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/ShipClassfication/Checkpoints/Faster_RCNN_1.pth\"\n",
        "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Set a threshold for predictions\n",
        "    predictor = DefaultPredictor(cfg)\n",
        "\n",
        "    # Load and predict on a new image\n",
        "    image_path = \"/content/drive/MyDrive/ShipClassfication/SAR/Val/72dba3e82f782f67t_stacked.tif\"\n",
        "    image = custom_read_image(image_path)\n",
        "    outputs = predictor(image)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muL0kwr4BJ7G"
      },
      "outputs": [],
      "source": [
        "# Load model\n",
        "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/ShipClassfication/Checkpoints/Faster_RCNN_1.pth\"\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "# Create evaluator and test loader\n",
        "evaluator = COCOEvaluator(\"cascade_val_dataset\", cfg, False, output_dir=\"/content/drive/MyDrive/ShipClassfication/Checkpoints/SAR/7\")\n",
        "test_loader = build_detection_test_loader(cfg, \"cascade_val_dataset\")\n",
        "\n",
        "# Perform evaluation\n",
        "metrics = inference_on_dataset(predictor.model, test_loader, evaluator)\n",
        "\n",
        "precision = metrics[\"bbox\"][\"AP\"]\n",
        "recall = metrics[\"bbox\"][\"AR\"]\n",
        "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqedLgdWBLQv"
      },
      "outputs": [],
      "source": [
        "   # Visualize model on test data\n",
        "\n",
        "    v = Visualizer(image[:, :, ::-1], MetadataCatalog.get(\"my_train_dataset\"), scale=1.2)\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "\n",
        "    meta = image.meta.copy()\n",
        "    meta.update({\n",
        "        'count': 3,\n",
        "        'dtype': image.read(1).dtype,\n",
        "    })\n",
        "\n",
        "    with rasterio.open(f\"{generation}_ouput.tif\", 'w', **meta) as dst:\n",
        "        dst.write(image)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}